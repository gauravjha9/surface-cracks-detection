{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea9184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1fed075",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dir = './cracks-datasets/Positive/'\n",
    "negative_dir = './cracks-datasets/Negative/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7457c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_img_path = [img_path for img_path in os.listdir(positive_dir)]\n",
    "neg_img_path = [img_path for img_path in os.listdir(negative_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4caa4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_images = []\n",
    "\n",
    "for img_path in pos_img_path:\n",
    "    img = cv2.imread(f'{positive_dir}{img_path}')\n",
    "    resize_img = cv2.resize(img, (64, 64))\n",
    "    gray_img = cv2.cvtColor(resize_img, cv2.COLOR_BGR2GRAY)\n",
    "    scaled_img = gray_img/255\n",
    "    pos_images.append(scaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34970a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_images = []\n",
    "\n",
    "for img_path in neg_img_path:\n",
    "    img = cv2.imread(f'{negative_dir}{img_path}')\n",
    "    resize_img = cv2.resize(img, (64, 64))\n",
    "    gray_img = cv2.cvtColor(resize_img, cv2.COLOR_BGR2GRAY)\n",
    "    scaled_img = gray_img/255\n",
    "    neg_images.append(scaled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e8d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866d6fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_images))\n",
    "print(len(neg_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b150acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c180e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(pos_images + neg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71b8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1] * len(pos_images) + [0] * len(neg_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af3a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700ee394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06175e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 64, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c774efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34165d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "785d4531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 81s 80ms/step - loss: 0.5150 - accuracy: 0.7726\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.4051 - accuracy: 0.8562\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.3768 - accuracy: 0.8688\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.3579 - accuracy: 0.8804\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.3512 - accuracy: 0.8808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bd37e0bf10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(64, 64)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64bdb277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 20s 79ms/step - loss: 0.3433 - accuracy: 0.8979\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60e11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4f7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    resize_img = cv2.resize(img, (64, 64))\n",
    "    gray_img = cv2.cvtColor(resize_img, cv2.COLOR_BGR2GRAY)\n",
    "    scaled_img = gray_img/255\n",
    "    preprocessed_img = scaled_img.reshape(1, 64, 64)\n",
    "    \n",
    "    return preprocessed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf223a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2fab9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_img_path = './cracks-datasets/Positive/00009.jpg';\n",
    "neg_test_img_path = './cracks-datasets/Negative/10008.jpg';\n",
    "\n",
    "pos_test_img = get_preprocessed_img(pos_test_img_path)\n",
    "neg_test_img = get_preprocessed_img(neg_test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37c79646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6cf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a767508d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict([pos_test_img])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict([pos_test_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c11d866d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00019334]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([neg_test_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e2b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21fb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11f69519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 20s 76ms/step - loss: 0.5925 - accuracy: 0.7445\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.4653 - accuracy: 0.8410\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 20s 79ms/step - loss: 0.4230 - accuracy: 0.8596\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3952 - accuracy: 0.8721\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.3878 - accuracy: 0.8690\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3728 - accuracy: 0.8787\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3599 - accuracy: 0.8857\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3537 - accuracy: 0.8903\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 20s 79ms/step - loss: 0.3497 - accuracy: 0.8901\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3466 - accuracy: 0.8904\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.3432 - accuracy: 0.8881\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3414 - accuracy: 0.8901\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 20s 79ms/step - loss: 0.3333 - accuracy: 0.8953\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3359 - accuracy: 0.8930\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.3326 - accuracy: 0.8928\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.3315 - accuracy: 0.8942\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 19s 78ms/step - loss: 0.3275 - accuracy: 0.8957\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.3250 - accuracy: 0.8961\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.3211 - accuracy: 0.8981\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 20s 79ms/step - loss: 0.3261 - accuracy: 0.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bd3b9b7310>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3fcd44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "884ad944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 24s 46ms/step - loss: 0.5472 - accuracy: 0.7481\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.4270 - accuracy: 0.8528\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.3937 - accuracy: 0.8687\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.3724 - accuracy: 0.8773\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 0.3641 - accuracy: 0.8785\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 25s 49ms/step - loss: 0.3553 - accuracy: 0.8806\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.3452 - accuracy: 0.8895\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 26s 51ms/step - loss: 0.3501 - accuracy: 0.8824\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 0.3363 - accuracy: 0.8925\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 25s 49ms/step - loss: 0.3353 - accuracy: 0.8913\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 25s 51ms/step - loss: 0.3302 - accuracy: 0.8927\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 25s 51ms/step - loss: 0.3267 - accuracy: 0.8939\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 0.3272 - accuracy: 0.8935\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 0.3225 - accuracy: 0.8952\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 0.3187 - accuracy: 0.8969\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 27s 53ms/step - loss: 0.3251 - accuracy: 0.8942\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 0.3170 - accuracy: 0.8972\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 0.3136 - accuracy: 0.8988\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 26s 51ms/step - loss: 0.3119 - accuracy: 0.8996\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 0.3153 - accuracy: 0.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bd3c23fa90>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838834d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5ed23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5729166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 168s 166ms/step - loss: 0.4807 - accuracy: 0.7671\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 169s 169ms/step - loss: 0.3364 - accuracy: 0.8572\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.3029 - accuracy: 0.8780\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.2893 - accuracy: 0.8851\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.2857 - accuracy: 0.8865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bd3c73f390>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7632fef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f124f47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 47s 180ms/step - loss: 0.6560 - accuracy: 0.6926\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 0.3955 - accuracy: 0.8496\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 0.3472 - accuracy: 0.8558\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 0.3064 - accuracy: 0.8747\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 0.3003 - accuracy: 0.8783\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.2923 - accuracy: 0.8836\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.2810 - accuracy: 0.8879\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.2501 - accuracy: 0.9045\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.2365 - accuracy: 0.9095\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.2192 - accuracy: 0.9182\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.2229 - accuracy: 0.9160\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.2048 - accuracy: 0.9248\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 49s 194ms/step - loss: 0.1990 - accuracy: 0.9262\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 49s 196ms/step - loss: 0.2004 - accuracy: 0.9265\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.2060 - accuracy: 0.9245\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 49s 196ms/step - loss: 0.2156 - accuracy: 0.9199\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 49s 194ms/step - loss: 0.1993 - accuracy: 0.9277\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 49s 194ms/step - loss: 0.2013 - accuracy: 0.9273\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.1973 - accuracy: 0.9280\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.1883 - accuracy: 0.9321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bd3c588710>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60486a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1534b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9cb927b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 305s 303ms/step - loss: 0.3038 - accuracy: 0.8902\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 266s 266ms/step - loss: 0.1879 - accuracy: 0.9390\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 265s 265ms/step - loss: 0.1654 - accuracy: 0.9482\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 265s 265ms/step - loss: 0.1542 - accuracy: 0.9504\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 265s 265ms/step - loss: 0.1446 - accuracy: 0.9554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bd3c017b50>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='valid', input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a71db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be4e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 304s 600ms/step - loss: 0.1042 - accuracy: 0.9605\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 300s 601ms/step - loss: 0.0411 - accuracy: 0.9881\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 312s 624ms/step - loss: 0.0362 - accuracy: 0.9895\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 298s 595ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 294s 587ms/step - loss: 0.0180 - accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20e6948a310>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e62c0761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 38s 151ms/step - loss: 0.0107 - accuracy: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010657215490937233, 0.9962499737739563]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa6fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb2f84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_img_path = './cracks-datasets/Positive/00510.jpg';\n",
    "neg_test_img_path = './cracks-datasets/Negative/10054.jpg';\n",
    "\n",
    "pos_test_img = get_preprocessed_img(pos_test_img_path)\n",
    "neg_test_img = get_preprocessed_img(neg_test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9f2fa2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([pos_test_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1c101382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 215ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00028456]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([neg_test_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ee04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "955fce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00045212]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[5001].reshape(1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232e1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d18e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc614a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c53fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7fe86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "49be0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_img_path = './test-img/pos-1.jfif';\n",
    "# pos_test_img_path = './test-img/pos-2.jpg';\n",
    "# pos_test_img_path = './test-img/pos-3.jfif';\n",
    "# pos_test_img_path = './test-img/pos-4.webp';\n",
    "# pos_test_img_path = './test-img/pos-5.png';\n",
    "\n",
    "\n",
    "neg_test_img_path = './test-img/neg-1.jfif';\n",
    "\n",
    "\n",
    "pos_test_img = get_preprocessed_img(pos_test_img_path)\n",
    "# neg_test_img = get_preprocessed_img(neg_test_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a95cda7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pos_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "87885487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00056521]], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(neg_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef9110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859a1d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb42efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_test[5]\n",
    "\n",
    "\n",
    "cv2.imshow(\"test\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "733b3e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d97152bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1ec4404d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495a1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7a246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad7e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c39107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624ea8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "89db50f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n",
      "Mask dtype: uint8\n",
      "Mask shape: ()\n",
      "Mask unique values: [255]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'findContours'\n> Overload resolution failed:\n>  - image is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'image'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask unique values:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39munique(mask))\n\u001b[0;32m     14\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(pos_test_img_path)\n\u001b[1;32m---> 16\u001b[0m contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(mask, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cnt \u001b[38;5;129;01min\u001b[39;00m contours:\n\u001b[0;32m     18\u001b[0m     x, y, w, h \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mboundingRect(cnt)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'findContours'\n> Overload resolution failed:\n>  - image is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'image'\n"
     ]
    }
   ],
   "source": [
    "pos_test_img_path = './test-img/pos-1.jfif';\n",
    "pos_test_img = get_preprocessed_img(pos_test_img_path)\n",
    "\n",
    "\n",
    "pred = model.predict(pos_test_img)\n",
    "\n",
    "mask = (np.squeeze(pred) > 0.5).astype(np.uint8) * 255\n",
    "mask = mask.astype(np.uint8)\n",
    "\n",
    "print(\"Mask dtype:\", mask.dtype)\n",
    "print(\"Mask shape:\", mask.shape)\n",
    "print(\"Mask unique values:\", np.unique(mask))\n",
    "\n",
    "image = cv2.imread(pos_test_img_path)\n",
    "\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "print(contours)\n",
    "    \n",
    "cv2.imshow(\"Detected Crack\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb155a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89629399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1] + 1, step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0] + 1, step_size):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "# Load and prepare test image\n",
    "image = cv2.imread('./test-img/pos-1.jfif')\n",
    "image = cv2.resize(image, (256, 256))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "normalized = gray / 255.0\n",
    "\n",
    "window_size = (64, 64)\n",
    "step_size = 16  # Overlapping windows for better coverage\n",
    "\n",
    "for (x, y, window) in sliding_window(normalized, step_size, window_size):\n",
    "    patch = window.reshape(1, 64, 64, 1)  # Add batch and channel dimensions\n",
    "    pred = model.predict(patch, verbose=0)[0][0]\n",
    "    if pred > 0.5:\n",
    "        cv2.rectangle(image, (x, y), (x + 64, y + 64), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Detected Crack Regions\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9d84c895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3890ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1] + 1, step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0] + 1, step_size):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "# Load and prepare test image\n",
    "image = cv2.imread('./test-img/pos-3.jfif')\n",
    "image = cv2.resize(image, (256, 256))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "normalized = gray / 255.0\n",
    "\n",
    "window_size = (64, 64)\n",
    "step_size = 16\n",
    "\n",
    "crack_boxes = []\n",
    "\n",
    "for (x, y, window) in sliding_window(normalized, step_size, window_size):\n",
    "    patch = window.reshape(1, 64, 64, 1)\n",
    "    pred = model.predict(patch, verbose=0)[0][0]\n",
    "    if pred > 0.5:\n",
    "        crack_boxes.append((x, y, x + 64, y + 64))\n",
    "\n",
    "# Merge all detected boxes into one bounding box\n",
    "if crack_boxes:\n",
    "    x1 = min(box[0] for box in crack_boxes)\n",
    "    y1 = min(box[1] for box in crack_boxes)\n",
    "    x2 = max(box[2] for box in crack_boxes)\n",
    "    y2 = max(box[3] for box in crack_boxes)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Detected Crack Region\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a0180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744e2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b6c842b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 65536 into shape (1,64,64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(input_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      8\u001b[0m normalized \u001b[38;5;241m=\u001b[39m gray \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m----> 9\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m normalized\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Predict mask\u001b[39;00m\n\u001b[0;32m     12\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_tensor, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m, :, :, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 65536 into shape (1,64,64,1)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load original image\n",
    "image = cv2.imread('./test-img/pos-1.jfif')\n",
    "input_image = cv2.resize(image, (256, 256))\n",
    "gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "normalized = gray / 255.0\n",
    "input_tensor = normalized.reshape(1, 64, 64, 1)\n",
    "\n",
    "# Predict mask\n",
    "pred = model.predict(input_tensor, verbose=0)[0, :, :, 0]\n",
    "\n",
    "# Threshold the prediction\n",
    "mask = (pred > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "# Find contours on the mask\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw one bounding box around the largest contour (or all combined)\n",
    "if contours:\n",
    "    all_points = np.concatenate(contours)\n",
    "    x, y, w, h = cv2.boundingRect(all_points)\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Crack Detected\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8915512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f1f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d02457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba991f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
